{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65967224",
   "metadata": {},
   "source": [
    "functions needed for testing in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b128a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works in jupyter-lab on webdev-clone conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebde659c-d3b4-4123-8384-c1046753bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "dual-energy              /home/brunocarlos_lnls/.conda/envs/dual-energy\n",
      "gabor-seg                /home/brunocarlos_lnls/.conda/envs/gabor-seg\n",
      "legacy                   /home/brunocarlos_lnls/.conda/envs/legacy\n",
      "web-neuroglancer         /home/brunocarlos_lnls/.conda/envs/web-neuroglancer\n",
      "webdev                   /home/brunocarlos_lnls/.conda/envs/webdev\n",
      "webdev-clone          *  /home/brunocarlos_lnls/.conda/envs/webdev-clone\n",
      "base                     /opt/conda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1819636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<setuptools.extension.Extension('sscAnnotat3D.app') at 0x7fe15d5be220>, <setuptools.extension.Extension('sscAnnotat3D.__version__') at 0x7fe15d512b80>, <setuptools.extension.Extension('sscAnnotat3D.aux_functions') at 0x7fe15d512df0>, <setuptools.extension.Extension('sscAnnotat3D.utils') at 0x7fe15d512e20>, <setuptools.extension.Extension('sscAnnotat3D.__init__') at 0x7fe15d512e50>, <setuptools.extension.Extension('sscAnnotat3D.superpixels') at 0x7fe15d512e80>, <setuptools.extension.Extension('sscAnnotat3D.label') at 0x7fe15d512eb0>, <setuptools.extension.Extension('sscAnnotat3D.binary') at 0x7fe15d512ee0>, <setuptools.extension.Extension('sscAnnotat3D.progressbar') at 0x7fe15d512d90>]\n",
      "[]\n",
      "[<setuptools.extension.Extension('sscAnnotat3D.repository.data_repo') at 0x7fe15d512dc0>, <setuptools.extension.Extension('sscAnnotat3D.repository.__init__') at 0x7fe15d5123d0>, <setuptools.extension.Extension('sscAnnotat3D.repository.module_repo') at 0x7fe15d512d30>]\n",
      "[<setuptools.extension.Extension('sscAnnotat3D.api.superpixel') at 0x7fe15d512f10>, <setuptools.extension.Extension('sscAnnotat3D.api.io') at 0x7fe15d512c10>, <setuptools.extension.Extension('sscAnnotat3D.api.deep') at 0x7fe15d512f70>, <setuptools.extension.Extension('sscAnnotat3D.api.__init__') at 0x7fe15d512f40>, <setuptools.extension.Extension('sscAnnotat3D.api.remotevis') at 0x7fe15d512400>, <setuptools.extension.Extension('sscAnnotat3D.api.annotation') at 0x7fe15d512fa0>, <setuptools.extension.Extension('sscAnnotat3D.api.filters') at 0x7fe15d512fd0>, <setuptools.extension.Extension('sscAnnotat3D.api.image') at 0x7fe15d525040>]\n",
      "[<setuptools.extension.Extension('sscAnnotat3D.api.modules.superpixel_segmentation_module') at 0x7fe15d525070>, <setuptools.extension.Extension('sscAnnotat3D.api.modules.pixel_segmentation_module') at 0x7fe15d5250d0>, <setuptools.extension.Extension('sscAnnotat3D.api.modules.__init__') at 0x7fe15d5250a0>]\n",
      "[]\n",
      "[<setuptools.extension.Extension('sscAnnotat3D.modules.annotation_module') at 0x7fe15d525100>, <setuptools.extension.Extension('sscAnnotat3D.modules.classifier_segmentation_module') at 0x7fe15d525160>, <setuptools.extension.Extension('sscAnnotat3D.modules.deep_network_module') at 0x7fe15d525130>, <setuptools.extension.Extension('sscAnnotat3D.modules.superpixel_segmentation_module') at 0x7fe15d525190>, <setuptools.extension.Extension('sscAnnotat3D.modules.segmentation_module') at 0x7fe15d5251c0>, <setuptools.extension.Extension('sscAnnotat3D.modules.pixel_segmentation_module') at 0x7fe15d5251f0>, <setuptools.extension.Extension('sscAnnotat3D.modules.__init__') at 0x7fe15d525220>]\n",
      "[<setuptools.extension.Extension('sscAnnotat3D.deeplearning.deeplearning_workspace_dialog') at 0x7fe15d525250>, <setuptools.extension.Extension('sscAnnotat3D.deeplearning.__init__') at 0x7fe15d525280>]\n",
      "[<setuptools.extension.Extension('sscAnnotat3D.cython.__init__') at 0x7fe15d5252b0>, <setuptools.extension.Extension('sscAnnotat3D.cython.annotation') at 0x7fe15d525310>, <setuptools.extension.Extension('sscAnnotat3D.cython.annotation') at 0x7fe15d5252e0>]\n",
      "Compiling sscAnnotat3D/repository/data_repo.py because it changed.\n",
      "[1/1] Cythonizing sscAnnotat3D/repository/data_repo.py\n",
      "/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/setuptools/dist.py:680: SetuptoolsDeprecationWarning: As setuptools moves its configuration towards `pyproject.toml`,\n",
      "`setuptools.config.parse_configuration` became deprecated.\n",
      "\n",
      "For the time being, you can use the `setuptools.config.setupcfg` module\n",
      "to access a backward compatible API, but this module is provisional\n",
      "and might be removed in the future.\n",
      "\n",
      "  parse_configuration(self, self.command_options,\n",
      "running install\n",
      "running build\n",
      "running build_py\n",
      "package init file 'sscAnnotat3D/colormaps/__init__.py' not found (or not a regular file)\n",
      "package init file 'sscAnnotat3D/static/__init__.py' not found (or not a regular file)\n",
      "package init file 'sscAnnotat3D/templates/__init__.py' not found (or not a regular file)\n",
      "running egg_info\n",
      "writing sscAnnotat3D.egg-info/PKG-INFO\n",
      "writing dependency_links to sscAnnotat3D.egg-info/dependency_links.txt\n",
      "writing requirements to sscAnnotat3D.egg-info/requires.txt\n",
      "writing top-level names to sscAnnotat3D.egg-info/top_level.txt\n",
      "reading manifest file 'sscAnnotat3D.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n",
      "writing manifest file 'sscAnnotat3D.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "building 'sscAnnotat3D.repository.data_repo' extension\n",
      "gcc -pthread -B /home/brunocarlos_lnls/.conda/envs/webdev-clone/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /home/brunocarlos_lnls/.conda/envs/webdev-clone/include -I/home/brunocarlos_lnls/.conda/envs/webdev-clone/include -fPIC -O2 -isystem /home/brunocarlos_lnls/.conda/envs/webdev-clone/include -fPIC -I/home/brunocarlos_lnls/.conda/envs/webdev-clone/include/python3.9 -c sscAnnotat3D/repository/data_repo.c -o build/temp.linux-x86_64-3.9/sscAnnotat3D/repository/data_repo.o\n",
      "gcc -pthread -B /home/brunocarlos_lnls/.conda/envs/webdev-clone/compiler_compat -shared -Wl,-rpath,/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib -Wl,-rpath-link,/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib -L/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib -L/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib -Wl,-rpath,/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib -Wl,-rpath-link,/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib -L/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib build/temp.linux-x86_64-3.9/sscAnnotat3D/repository/data_repo.o -o build/lib.linux-x86_64-3.9/sscAnnotat3D/repository/data_repo.cpython-39-x86_64-linux-gnu.so\n",
      "running install_lib\n",
      "copying build/lib.linux-x86_64-3.9/sscAnnotat3D/repository/data_repo.cpython-39-x86_64-linux-gnu.so -> /home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/sscAnnotat3D/repository\n",
      "running install_egg_info\n",
      "removing '/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/sscAnnotat3D-1.3.0-py3.9.egg-info' (and everything under it)\n",
      "Copying sscAnnotat3D.egg-info to /home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/sscAnnotat3D-1.3.0-py3.9.egg-info\n",
      "running install_scripts\n",
      "    _                      _        _   _____ ____\n",
      "   / \\   _ __  _ __   ___ | |_ __ _| |_|___ /|  _ \\\n",
      "  / _ \\ | '_ \\| '_ \\ / _ \\| __/ _` | __| |_ \\| | | |\n",
      " / ___ \\| | | | | | | (_) | || (_| | |_ ___) | |_| |\n",
      "/_/   \\_\\_| |_|_| |_|\\___/ \\__\\__,_|\\__|____/|____/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd ../../ && python setup.py install && cd sscAnnotat3D/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e8f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Prop functions and objects for prototyping in this notebook\n",
    "\"\"\"\n",
    "def jsonify(obj):\n",
    "    # overwriting for tests using jupyter\n",
    "    return obj\n",
    "\n",
    "def handle_exception(msg):\n",
    "    print('error_msg: {} '.format(msg))\n",
    "\n",
    "class requestClass():\n",
    "    def __init__(self):\n",
    "        self.json = None\n",
    "\n",
    "    def set_json(self, newdict):\n",
    "        self.json = newdict\n",
    "        \n",
    "    def append_json(self, newdict):\n",
    "        self.json = {**self.json, **newdict}\n",
    "\n",
    "    def clear(self):\n",
    "        self.json = None\n",
    "\n",
    "global request \n",
    "request = requestClass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968c5f9",
   "metadata": {},
   "source": [
    "copying deep.py and deactivating flask functionalities and derived functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "797b05a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This script contains some back-end functions for the deep learning module\n",
    "\n",
    "@authors : Gabriel Borin Macedo (gabriel.macedo@lnls.br or borinmacedo@gmail.com)\n",
    "         : Bruno Carlos (bruno.carlos@lnls.br)\n",
    "\n",
    "TODO : Don't forget to document the functions\n",
    "\n",
    "\"\"\"\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# from flask import Blueprint, jsonify, request\n",
    "# from flask_cors import cross_origin\n",
    "from werkzeug.exceptions import BadRequest\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from sscIO.io import read_volume\n",
    "from sscDeepsirius.cython import standardize\n",
    "from sscAnnotat3D.repository import data_repo\n",
    "from sscDeepsirius.utils import dataset, image, augmentation\n",
    "from sscDeepsirius.controller.inference_controller import InferenceController\n",
    "from sscDeepsirius.controller.host_network_controller import HostNetworkController \n",
    "from sscAnnotat3D.deeplearning import DeepLearningWorkspaceDialog\n",
    "\n",
    "\n",
    "# app = Blueprint('deep', __name__)\n",
    "\n",
    "def init_logger(init_msg : str = '\\nStarting message logger queue.\\n'):\n",
    "    data_repo.init_logger(init_msg)\n",
    "\n",
    "def log_msg(msg):\n",
    "    data_repo.set_log_message(msg)\n",
    "\n",
    "\n",
    "# @app.route(\"/read_log_queue\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def read_log_queue():\n",
    "    \"\"\"\n",
    "        Reads from a queue of messages stored on data_repo. \n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "            (str): An empty string if the queue is empty.\n",
    "    \"\"\"\n",
    "    msg = data_repo.dequeue_log_message()\n",
    "    if msg == None:\n",
    "        return ''\n",
    "    \n",
    "    return msg\n",
    "\n",
    "\n",
    "# @app.errorhandler(BadRequest)\n",
    "def handle_exception(error_msg: str):\n",
    "    \"\"\"\n",
    "    Function to handle error exception and returns to the user\n",
    "\n",
    "    Args:\n",
    "        error_msg (str): variable that contains the error\n",
    "\n",
    "    Returns:\n",
    "        (tuple): This function returns a tuple that contains the error as a JSON and an int 400\n",
    "\n",
    "    \"\"\"\n",
    "    return jsonify({\"error_msg\": error_msg}), 400\n",
    "\n",
    "\n",
    "# app.register_error_handler(400, handle_exception)\n",
    "\n",
    "\n",
    "def _convert_dtype_to_str(img_dtype: np.dtype):\n",
    "    \"\"\"\n",
    "    Build-in function to convert dtype to a str\n",
    "\n",
    "    Args:\n",
    "        img_dtype (np.dtype): np.dtype object that contains\n",
    "\n",
    "    Returns:\n",
    "        (str): returns the str version of the dtype\n",
    "\n",
    "    \"\"\"\n",
    "    return np.dtype(img_dtype).name\n",
    "\n",
    "\n",
    "def _debugger_print(msg: str, payload: any):\n",
    "    \"\"\"\n",
    "    Build-in function to user as debugger\n",
    "\n",
    "    Args:\n",
    "        msg(str): string message to user in debugger\n",
    "        payload(any): a generic payload\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"\\n----------------------------------------------------------\")\n",
    "    print(\"{} : {}\".format(msg, payload))\n",
    "    print(\"----------------------------------------------------------\\n\")\n",
    "\n",
    "# removed from io.py and placed here\n",
    "# @app.route(\"/open_new_workspace\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def open_new_workspace():\n",
    "    \"\"\"\n",
    "    Function that opens a new workspace\n",
    "\n",
    "    Notes:\n",
    "        the request.json[\"workspace_path\"] receives only the parameter \"selected_labels\"(str)\n",
    "\n",
    "    Returns:\n",
    "        (str): returns a string that contains the new workspace path\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        workspace_path = request.json[\"workspace_path\"]\n",
    "        workspace_root = request.json[\"workspace_root\"]\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    if (workspace_root == \"\"):\n",
    "        return handle_exception(\"Empty path isn't valid !\")\n",
    "\n",
    "    deep_model = DeepLearningWorkspaceDialog()\n",
    "    save_status, error_desc = deep_model.open_new_workspace(workspace_path)\n",
    "\n",
    "    if (save_status):\n",
    "        data_repo.set_deep_model_info(key='workspace_path', data=workspace_path)\n",
    "        return jsonify(workspace_path)\n",
    "\n",
    "    return handle_exception(\"unable to create the Workspace ! : {}\".format(error_desc))\n",
    "\n",
    "\n",
    "# @app.route(\"/load_workspace\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def load_workspace():\n",
    "    \"\"\"\n",
    "    Function that loads a created workspace\n",
    "\n",
    "    Notes:\n",
    "        the request.json[\"workspace_path\"] receives only the parameter \"selected_labels\"(str)\n",
    "\n",
    "    Returns:\n",
    "        (str): returns a string that contains the loaded workspace path\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        workspace_path = request.json[\"workspace_path\"]\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    deep_model = DeepLearningWorkspaceDialog()\n",
    "    check_valid_workspace = deep_model.check_workspace(workspace_path)\n",
    "\n",
    "    if (check_valid_workspace):\n",
    "        data_repo.set_deep_model_info(key='workspace_path', data=workspace_path)\n",
    "        return jsonify(check_valid_workspace)\n",
    "\n",
    "    return handle_exception(\"path \\\"{}\\\" is a invalid workspace path!\".format(workspace_path))\n",
    "\n",
    "\n",
    "def _augmenters_list(augmentation_vec: list = None, ion_range_vec: list = None):\n",
    "    \"\"\"\n",
    "    Build-in function that formats the front-end data into the correct structure in the function augment_web\n",
    "\n",
    "    Args:\n",
    "        augmentation_vec (list): a list that contains all the elements to augment\n",
    "        ion_range_vec (list): a list that contains the value of ion-rage of some augment parameters\n",
    "\n",
    "    Returns:\n",
    "        (list): returns a list that contains the params to augment and the respective values\n",
    "\n",
    "    \"\"\"\n",
    "    augmenters = []\n",
    "\n",
    "    # vertical-flip option\n",
    "    if (augmentation_vec[0][\"isChecked\"]):\n",
    "        augmenters.append(\"vertical-flip\")\n",
    "\n",
    "    # horizontal-flip option\n",
    "    if (augmentation_vec[1][\"isChecked\"]):\n",
    "        augmenters.append(\"horizontal-flip\")\n",
    "\n",
    "    # rotate-90-degrees option\n",
    "    if (augmentation_vec[2][\"isChecked\"]):\n",
    "        augmenters.append(\"rotate-90-degrees\")\n",
    "\n",
    "    # rotate-less-90-degrees (rotate 270 degrees) option\n",
    "    if (augmentation_vec[3][\"isChecked\"]):\n",
    "        augmenters.append(\"rotate-less-90-degrees\")\n",
    "\n",
    "    # contrast option\n",
    "    if (augmentation_vec[4][\"isChecked\"]):\n",
    "        # c_min, c_max = ion_range_vec[0][\"ionRangeLimit\"].values\n",
    "        c_lower, c_upper = ion_range_vec[0][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"contrast\",\n",
    "                 contrast=(c_lower, c_upper)))\n",
    "        _debugger_print(\"test for ion-range in contrast\", augmentation_vec[-1])\n",
    "\n",
    "    # linear-contrast option\n",
    "    if (augmentation_vec[5][\"isChecked\"]):\n",
    "        c_lower, c_upper = ion_range_vec[1][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"linear-contrast\",\n",
    "                 linearContrast=(c_lower, c_upper)))\n",
    "        _debugger_print(\"test for ion-range in linear-contrast\", augmentation_vec[-1])\n",
    "\n",
    "    # dropout option\n",
    "    if (augmentation_vec[6][\"isChecked\"]):\n",
    "        c_lower, c_upper = ion_range_vec[2][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"dropout\",\n",
    "                 dropout=(c_lower, c_upper)))\n",
    "        _debugger_print(\"test for ion-range in dropout\", augmentation_vec[-1])\n",
    "\n",
    "    # gaussian-blur option\n",
    "    if (augmentation_vec[7][\"isChecked\"]):\n",
    "        c_lower, c_upper = ion_range_vec[3][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"gaussian-blur\",\n",
    "                 sigma=(c_lower, c_upper)))\n",
    "        _debugger_print(\"test for ion-range in gaussian-blur\", augmentation_vec[-1])\n",
    "\n",
    "    # average-blur option\n",
    "    if (augmentation_vec[8][\"isChecked\"]):\n",
    "        c_lower, c_upper = ion_range_vec[4][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"average-blur\",\n",
    "                 k=(c_lower, c_upper)))\n",
    "        _debugger_print(\"test for ion-range in average-blur\", augmentation_vec[-1])\n",
    "\n",
    "    # additive-poisson-noise option\n",
    "    if (augmentation_vec[9][\"isChecked\"]):\n",
    "        c_lower, c_upper = ion_range_vec[5][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"additive-poisson-noise\",\n",
    "                 k=(c_lower, c_upper)))\n",
    "        _debugger_print(\"test for ion-range in additive-poisson-noise\", augmentation_vec[-1])\n",
    "\n",
    "    # elastic-deformation option\n",
    "    if (augmentation_vec[10][\"isChecked\"]):\n",
    "        c_lower_alpha, c_upper_alpha = ion_range_vec[6][\"actualRangeVal\"].values()\n",
    "        c_lower_sigma, c_upper_sigma = ion_range_vec[7][\"actualRangeVal\"].values()\n",
    "        augmenters.append(\n",
    "            dict(type=\"elastic-deformation\",\n",
    "                 alpha=(c_lower_alpha, c_upper_alpha),\n",
    "                 sigma=(c_lower_sigma, c_upper_sigma)))\n",
    "        _debugger_print(\"test for ion-range in elastic-deformation\", augmentation_vec[-1])\n",
    "\n",
    "    _debugger_print(\"augmenters param\", augmenters)\n",
    "    return augmenters\n",
    "\n",
    "\n",
    "# @app.route(\"/create_dataset\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def create_dataset():\n",
    "    \"\"\"\n",
    "    Function that creates the .h5 dataset\n",
    "\n",
    "    Notes:\n",
    "        This function is used in DatasetComp.tsx\n",
    "\n",
    "    Returns:\n",
    "        (dict): returns a dict that contains the dataset .h5 name. Otherwise, will return an error for the front-end\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        output = request.json[\"file_path\"]\n",
    "        sample = request.json[\"sample\"]\n",
    "        augmentation_vec = request.json[\"augmentation\"]\n",
    "        ion_range_vec = request.json[\"ion_range_vec\"]\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    size = (sample[\"patchSize\"][0], sample[\"patchSize\"][1], sample[\"patchSize\"][2])\n",
    "    num_classes = sample[\"nClasses\"]\n",
    "    nsamples = sample[\"sampleSize\"]\n",
    "    offset = (0, 0, 0)\n",
    "    logging.debug('size = {}, nsamples = {}'.format(size, sample[\"sampleSize\"]))\n",
    "    augmenter_params = _augmenters_list(augmentation_vec, ion_range_vec)\n",
    "\n",
    "    imgs = list(data_repo.get_all_dataset_data().values())\n",
    "    labels = list(data_repo.get_all_dataset_label().values())\n",
    "    weights = list(data_repo.get_all_dataset_weight().values())\n",
    "\n",
    "    data, error_status = dataset.create_dataset_web(imgs, labels, weights,\n",
    "                                            output, nsamples, num_classes,\n",
    "                                            size, offset)\n",
    "\n",
    "    if (not data):\n",
    "        return handle_exception(error_status)\n",
    "\n",
    "    initial_output = output\n",
    "    splited_str = output.split(\"/\")\n",
    "    dataset_name = splited_str[-1]\n",
    "    new_dataset_name = splited_str[-1].split(\".\")[0] + \"_augment\" + \".h5\"\n",
    "    output = output.replace(dataset_name, new_dataset_name)\n",
    "\n",
    "    if (augmenter_params):\n",
    "        data, error_status = augmentation.augment_web(output, initial_output, augmenter_params, data)\n",
    "\n",
    "    if (not data):\n",
    "        return handle_exception(error_status)\n",
    "\n",
    "    dataset.save_dataset(data)\n",
    "\n",
    "    return jsonify({\"datasetFilename\": initial_output.split(\"/\")[-1]})\n",
    "\n",
    "\n",
    "# @app.route(\"/open_inference_files/<file_id>\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def open_inference_files(file_id: str):\n",
    "    _debugger_print(\"new key\", file_id)\n",
    "    try:\n",
    "        file_path = request.json[\"image_path\"]\n",
    "    except:\n",
    "        return handle_exception(\"Error while trying to get the image path\")\n",
    "\n",
    "    try:\n",
    "        file_dtype = request.json[\"image_dtype\"]\n",
    "    except:\n",
    "        return handle_exception(\"Error while trying to get the image dtype\")\n",
    "\n",
    "    file = file_path.split(\"/\")[-1]\n",
    "    file_name, extension = os.path.splitext(file)\n",
    "\n",
    "    if (file == \"\"):\n",
    "        return handle_exception(\"Empty path isn't valid !\")\n",
    "\n",
    "    raw_extensions = [\".raw\", \".b\"]\n",
    "    tif_extensions = [\".tif\", \".tiff\", \".npy\", \".cbf\"]\n",
    "\n",
    "    extensions = [*raw_extensions, *tif_extensions]\n",
    "\n",
    "    if extension not in extensions:\n",
    "        return handle_exception(\"The extension {} isn't supported !\".format(extension))\n",
    "\n",
    "    error_msg = \"\"\n",
    "\n",
    "    try:\n",
    "        use_image_raw_parse = request.json[\"use_image_raw_parse\"]\n",
    "        if (extension in tif_extensions or use_image_raw_parse):\n",
    "            start = time.process_time()\n",
    "            image, info = read_volume(file_path, 'numpy')\n",
    "            end = time.process_time()\n",
    "            error_msg = \"No such file or directory {}\".format(file_path)\n",
    "\n",
    "            if (_convert_dtype_to_str(image.dtype) != file_dtype and (file_id == \"image\" or file_id == \"label\")):\n",
    "                image = image.astype(file_dtype)\n",
    "\n",
    "        else:\n",
    "            image_raw_shape = request.json[\"image_raw_shape\"]\n",
    "            start = time.process_time()\n",
    "            image, info = read_volume(file_path, 'numpy',\n",
    "                                               shape=(image_raw_shape[2], image_raw_shape[1], image_raw_shape[0]),\n",
    "                                               dtype=file_dtype)\n",
    "            end = time.process_time()\n",
    "            error_msg = \"Unable to reshape the volume {} into shape {} and type {}. \" \\\n",
    "                        \"Please change the dtype and shape and load the image again\".format(file, request.json[\n",
    "                \"image_raw_shape\"], file_dtype)\n",
    "        image_shape = image.shape\n",
    "        image_dtype = _convert_dtype_to_str(image.dtype)\n",
    "    except:\n",
    "        return handle_exception(error_msg)\n",
    "\n",
    "    image_info = {\"fileName\": file_name + extension,\n",
    "                  \"shape\": image_shape,\n",
    "                  \"type\": image_dtype,\n",
    "                  \"scan\": info,\n",
    "                  \"time\": np.round(end - start, 2),\n",
    "                  \"size\": np.round(image.nbytes / 1000000, 2),\n",
    "                  \"filePath\": file_path}\n",
    "\n",
    "    data_repo.set_inference_data(key=file_id, data=image)\n",
    "    data_repo.set_inference_info(key=file_id, data=image_info)\n",
    "\n",
    "    return jsonify(image_info)\n",
    "\n",
    "\n",
    "# @app.route(\"/close_inference_file/<file_id>\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def close_inference_file(file_id: str):\n",
    "    \"\"\"\n",
    "    Function that deletes a file in inference a menu using a key as string\n",
    "\n",
    "    Args:\n",
    "        file_id (str): string used as key to delete the file\n",
    "\n",
    "    Returns:\n",
    "        (str): Returns a string that contains the error or \"success on delete the key i in Input Image inference\"\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_repo.del_inference_data(file_id)\n",
    "        data_repo.del_inference_info(file_id)\n",
    "        return jsonify(\"success on delete the key {} in Input Image inference\".format(file_id))\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "\n",
    "# @app.route(\"/close_all_files_dataset\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def close_all_inference_files():\n",
    "    \"\"\"\n",
    "    Function that delete all the files in inference menu\n",
    "\n",
    "    Returns:\n",
    "        (str): Returns a string that contains the error or \"Success to delete all data\"\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_repo.del_all_inference_data()\n",
    "        data_repo.del_all_inference_info()\n",
    "        return jsonify(\"Success to delete all data\")\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "\n",
    "\n",
    "# @app.route(\"/get_available_gpus\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "    Function that verify all the available gpus for inference and show to the user\n",
    "\n",
    "    Returns:\n",
    "        (dict): returns a dict that contains all the gpus to use for inference\n",
    "\n",
    "    \"\"\"\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    list_devices = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "    gpus = []\n",
    "    gpu_device_names = []\n",
    "    i = 0\n",
    "    for device in list_devices:\n",
    "        gpu_number = int(device.split(\":\")[-1])\n",
    "        gpus.append(gpu_number)\n",
    "        gpu_device_names.append({\n",
    "            \"key\": i,\n",
    "            \"value\": \"GPU {}\".format(gpu_number),\n",
    "            \"label\": device\n",
    "        })\n",
    "        i+=1\n",
    "\n",
    "    # data_repo.set_inference_gpus(gpus)\n",
    "    data_repo.set_deep_model_info(key='available_gpus', data=gpus)\n",
    "    return jsonify(gpu_device_names) \n",
    "\n",
    "\n",
    "# @app.route(\"/get_frozen_data\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def get_frozen_data():\n",
    "    \"\"\"\n",
    "    Function that verify all the frozen data in frozen directory created in the workspace menu\n",
    "\n",
    "    Returns:\n",
    "        (dict): returns a dict with all the meta_files for the user to choose and use in inference\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        workspace_path = data_repo.get_deep_model_info('workspace_path')\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    try:\n",
    "        frozen_path_pb = glob.glob(workspace_path + \"frozen/*.pb\")\n",
    "        frozen_path_PB = glob.glob(workspace_path + \"frozen/*.PB\")\n",
    "        frozen_path = [*frozen_path_pb, *frozen_path_PB]\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    meta_files = []\n",
    "\n",
    "    for i in range(0, len(frozen_path)):\n",
    "        file_name = frozen_path[i].split(\"/\")[-1]\n",
    "        meta_files.append({\n",
    "            \"key\": i,\n",
    "            \"value\": file_name,\n",
    "            \"label\": file_name\n",
    "        })\n",
    "\n",
    "    return jsonify(meta_files)\n",
    "\n",
    "\n",
    "# @app.route(\"/run_inference\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def run_inference():\n",
    "    \"\"\"\n",
    "    Function that run the inference\n",
    "\n",
    "    Returns:\n",
    "        (str): returns a string \"successes\" if the operation occurs without any error and an exception otherwise\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = request.json[\"output\"]\n",
    "        patches = request.json[\"patches\"]\n",
    "        network = request.json[\"network\"]\n",
    "        isInferenceOpChecked = request.json[\"isInferenceOpChecked\"]\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    if (output[\"outputPath\"] == \"\"):\n",
    "        return handle_exception(\"Empty path isn't valid !\")\n",
    "\n",
    "    try:\n",
    "        workspace_path = data_repo.get_deep_model_info('workspace_path')\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "    \n",
    "    _depth_prob_map_dtype = {'16-bits': np.dtype('float16'), '32-bits': np.dtype('float32')}\n",
    "    images_list = [*data_repo.get_all_inference_keys()]\n",
    "    images_props = [*data_repo.get_all_inference_info()]\n",
    "    images_list_name = [*data_repo.get_all_inference_info()]\n",
    "    images_list_name = [x[\"filePath\"] for x in images_list_name]\n",
    "    output_folder = output[\"outputPath\"]\n",
    "    model_file_h5 = os.path.join(workspace_path, \"frozen\", network + \".meta.h5\")\n",
    "    model_file = os.path.join(workspace_path, \"frozen\", network)    \n",
    "    error_message = \"\"\n",
    "    try:\n",
    "        metadata = dataset.load_metadata(model_file_h5)\n",
    "    except Exception as e:\n",
    "        return handle_exception(str(e))\n",
    "\n",
    "    patch_size = metadata['patch_size']\n",
    "    num_classes = metadata.get('num_classes', 2)\n",
    "\n",
    "    border = (patches[\"patchBorder\"][0], patches[\"patchBorder\"][1], patches[\"patchBorder\"][2])\n",
    "    padding = (patches[\"volumePadding\"][0], patches[\"volumePadding\"][1], patches[\"volumePadding\"][2])\n",
    "\n",
    "    if (len(images_list) > 0):\n",
    "        if (any(np.array(padding) > np.array(patch_size))):\n",
    "            error_message = 'One of Volume Padding axis is greater than Patch Size axis'\n",
    "        elif (any(np.array(border) > np.array(patch_size))):\n",
    "            error_message = 'One of Patch Border axis is greater than Patch Size axis'\n",
    "        elif (output[\"probabilityMap\"] == False and output[\"label\"] == False):\n",
    "            error_message = 'Please select the output type'\n",
    "        else:\n",
    "            if output_folder:\n",
    "                logging.debug('{}'.format(output_folder))\n",
    "\n",
    "            else:\n",
    "                error_message = 'Please specify the output path.'\n",
    "\n",
    "    else:\n",
    "        error_message = 'Please specify the list of images to segment.'\n",
    "\n",
    "    if (error_message != \"\"):\n",
    "        _debugger_print(\"error in run_inference func\", error_message)\n",
    "        return handle_exception(error_message)\n",
    "\n",
    "    batch_size = metadata['batch_size']\n",
    "    input_node = metadata['input_node']\n",
    "    output_node = metadata['output_node']\n",
    "\n",
    "    mean = np.float32(metadata['mean'])\n",
    "    std = np.float32(metadata['std'])\n",
    "\n",
    "    logging.debug('images_list: {}'.format(images_list))\n",
    "    logging.debug('images_props: {}'.format(images_props))\n",
    "\n",
    "    gpus = data_repo.get_inference_gpus()\n",
    "\n",
    "    inference_controller = InferenceController(\"\",\n",
    "                                               \",\".join(map(str, gpus)),\n",
    "                                               use_tensorrt=isInferenceOpChecked)\n",
    "\n",
    "    inference_controller.load_graph(model_file, input_node + \":0\", output_node + \":0\")\n",
    "\n",
    "    try:\n",
    "        inference_controller.optimize_batch((batch_size, *patch_size),\n",
    "                                            border,\n",
    "                                            padding=padding,\n",
    "                                            num_classes=num_classes)\n",
    "    except:\n",
    "        return handle_exception(\"Not enough GPU memory to use in inference\")\n",
    "\n",
    "    for image_file_name, image_file, image_props_file in zip(images_list_name, images_list, images_props):\n",
    "        f, _ = os.path.splitext(os.path.basename(image_file_name))\n",
    "        data = data_repo.get_inference_data(image_file)\n",
    "        image_props = {\n",
    "            \"shape\": [image_props_file[\"shape\"][0], image_props_file[\"shape\"][1], image_props_file[\"shape\"][2]],\n",
    "            \"dtype\": data.dtype}\n",
    "\n",
    "        t1 = time.time()\n",
    "        t2 = time.time()\n",
    "        logging.debug('Read image: {}'.format(t2 - t1))\n",
    "        t1 = time.time()\n",
    "        # optimize to avoid unecessary copy\n",
    "        logging.debug('{}'.format(data.shape))\n",
    "        data = standardize(data, mean, std, 64)\n",
    "        t2 = time.time()\n",
    "        logging.debug('Rotate and cast image: {}'.format(t2 - t1)) \n",
    "        dtype = _depth_prob_map_dtype[output[\"outputBits\"]]\n",
    "\n",
    "        output_data = inference_controller.inference(data, output_dtype=dtype)\n",
    "\n",
    "        try:\n",
    "            image.save_inference(output_folder,\n",
    "                                 f,\n",
    "                                 output_data,\n",
    "                                 num_classes,\n",
    "                                 image_props,\n",
    "                                 save_prob_map=output[\"probabilityMap\"],\n",
    "                                 save_label=output[\"label\"],\n",
    "                                 output_dtype=dtype,\n",
    "                                 ext=output[\"outputExt\"][1:])\n",
    "        except Exception as e:\n",
    "            return handle_exception(\"Error to save the inference : {}\".format(str(e)))\n",
    "\n",
    "    return jsonify(\"successes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819f079",
   "metadata": {},
   "source": [
    "# network module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "eb511f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_network_controller():\n",
    "    \"\"\"\n",
    "    Access workspace on data repo, set up network controller and reads available nets\n",
    "    find workspace > creates a network controller, reads available networks and its custom parametes\n",
    "    \n",
    "    return available networks\n",
    "    \"\"\"\n",
    "    try:\n",
    "        workspace_path = data_repo.get_deep_model_info(key='workspace_path')\n",
    "    except Exception as e:\n",
    "        return handle_exception('Workspace path not found. {}'.format(str(e)))\n",
    "    \n",
    "    try:\n",
    "        network_controller = HostNetworkController(workspace=workspace_path, streaming_mode=True)\n",
    "    except Exception as e:\n",
    "        return handle_exception('Unable to load Network Controller from this workspace. {}'.format(str(e)))\n",
    "    \n",
    "    get_available_gpus() # stores gpu info on data_repo\n",
    "\n",
    "    data_repo.set_deep_model_info(key='network_controller', data=network_controller)\n",
    "    \n",
    "    return 'success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e2bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_network_controller():\n",
    "    return data_repo.get_deep_model_info(key='network_controller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0319ec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/get_available_networks\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def get_available_networks():\n",
    "    \"\"\"\n",
    "    Access workspace on data repo, set up network controller and reads available nets\n",
    "    find workspace > creates a network controller, reads available networks and its custom parametes\n",
    "    \n",
    "    return available networks\n",
    "    \"\"\"\n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    if not network_controller:\n",
    "        return handle_exception('Unable toload Network Controller. Make sure workspace is loaded.')\n",
    "    \n",
    "    return jsonify(network_controller.network_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900a2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/get_network_params\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def get_network_params(network_name):\n",
    "    # {k: self._custom_params_ui[k].currentText() for k in self._custom_params_ui}\n",
    "    # params = self._network_controller.network_list_params(network)\n",
    "    \n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    if not network_controller:\n",
    "        return handle_exception('Unable toload Network Controller. Make sure workspace is loaded.')\n",
    "    \n",
    "    return jsonify(network_controller.network_list_params(network_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c5865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/import_network\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def import_network():\n",
    "    import_network_path = request.json['import_network_path']\n",
    "    import_network_name = request.json['import_network_name']\n",
    "\n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    if not network_controller:\n",
    "        return handle_exception('Unable toload Network Controller. Make sure workspace is loaded.')\n",
    "\n",
    "    try:\n",
    "        network_controller.import_model(import_network_path, import_network_name)\n",
    "    except Exception as e:\n",
    "        return handle_exception('Unable to import network. {}'.format(str(e)))\n",
    "\n",
    "    return get_network_params(import_network_name) # make this call on sfetch().then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f4d20372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/import_dataset\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def import_dataset():\n",
    "    dataset_fpath = request.json['import_dataset_path']\n",
    "\n",
    "    thisdataset = dataset.load_dataset(dataset_fpath)\n",
    "    \n",
    "    logging.debug('RUN THREAD ... ')\n",
    "    logging.debug('{}'.format(thisdataset))\n",
    "\n",
    "    if dataset is None:\n",
    "        return \"Fail. Dataset not found\"\n",
    "\n",
    "    data = thisdataset['data']\n",
    "    logging.debug('Compute dataset info')\n",
    "\n",
    "    stats = dataset.get_stats(thisdataset)\n",
    "    \n",
    "    # legacy format:\n",
    "    # data_info = (data.shape[0], data.shape[1], data.shape[2:], stats['data_mean'], stats['data_std'],\n",
    "    #                    stats['data_min'], stats['data_max'], _dataset['num_classes'], stats['nlabels'],\n",
    "    #                    stats['label_count'], stats['weight_mean'], stats['weight_std'], stats['weight_min'],\n",
    "    #                    stats['weight_max']) #legacy qt code\n",
    "    \n",
    "    data_info_dict = {\n",
    "        '#_images'   : data.shape[0] ,\n",
    "        '#_samples'  : data.shape[1] ,\n",
    "        'Dimensions' : data.shape[2:],\n",
    "        'data_mean': stats['data_mean'],\n",
    "        'data_std' : stats['data_std'],\n",
    "        'data_min' : stats['data_min'],\n",
    "        'data_max' : stats['data_max'],\n",
    "        '#_classes': thisdataset['num_classes'], \n",
    "        '#_labels' : stats['nlabels'],\n",
    "        'hist' : stats['label_count'], \n",
    "        'weight_mean' : stats['weight_mean'], \n",
    "        'weight_std' : stats['weight_std'], \n",
    "        'weight_min' : stats['weight_min'],\n",
    "        'weight_max' : stats['weight_max']\n",
    "    }\n",
    "    \n",
    "    data_repo.set_deep_network_info('data_info_dict', data_info_dict)\n",
    "    data_repo.set_deep_network_info('dataset_fpath', dataset_fpath)\n",
    "    \n",
    "    logging.debug('Done ...')\n",
    "    return jsonify(data_info_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667af63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_cache_path():\n",
    "    \n",
    "    cache_path = request.json['cache_path']\n",
    "\n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    if not network_controller:\n",
    "        return handle_exception('Unable toload Network Controller. Make sure workspace is loaded.')\n",
    "    \n",
    "    network_controller.set_cache_base_dir(cache_path)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a878b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _deploy_new_instance(network_instance_name):\n",
    "    \"\"\"\n",
    "    Returns a new instance object from sscDeepsirius that carries information about the network to be trained.\n",
    "    \n",
    "    Args:\n",
    "        network_instance_name (str): This name is set in instance.network variable\n",
    "    Returns:\n",
    "        instance (Container() struct-like object)\n",
    "    \"\"\"\n",
    "    network_controller = _get_network_controller()\n",
    "    instance_container = network_controller.deploy_network_instance(network_instance_name)\n",
    "    \n",
    "    return network_controller.deploy_network_instance(network_instance_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1afdf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _destroy_instance(instance_name):\n",
    "    network_controller = _get_network_controller()\n",
    "    network_controller.destroy_network_instance(instance_name)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f39735a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_instance(network_instance_name):\n",
    "    \"\"\"\n",
    "    Sets new instance of a network, with information to be tracked on the repository and be accessible by the frontend\n",
    "    \n",
    "    instance is an struct like object used in the sscDeepsirius module, with attributes network, train, infer, freeze and finetune\n",
    "    \"\"\"\n",
    "    network_controller = _get_network_controller()\n",
    "    instance_container = network_controller.deploy_network_instance(network_instance_name)\n",
    "    \n",
    "    data_repo.set_deep_network_info(key='instance_container', data=instance_container)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524dd81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/set_tensorboard_server/<selected_network_name>\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def set_tensorboard_server(selected_network_name):\n",
    "    network_controller = _get_network_controller()\n",
    "    tensorboard_server_url = network_controller.start_tensorboard(selected_network_name)\n",
    "    logging.debug('Tensorboard: {}'.format(self._tensorboard_server))\n",
    "    logging.debug('Tensorboard URL: {}'.format(tensorboard_server_url))\n",
    "    return tensorboard_server_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "352914d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/go_training/\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def go_training():\n",
    "    \"\"\"\n",
    "        From request start training the network. \n",
    "    Request.json params: \n",
    "        network_name_selected (str) : \n",
    "        custom_params_selected (dict) :\n",
    "        training_params (dict) : \n",
    "    \"\"\"\n",
    "    # self._sentry_transaction = sentry_sdk.start_transaction(name='Training', op='deeplearning')\n",
    "    # self._sentry_transaction.__enter__() # why is it an object and do we tell it when to stop?\n",
    "    \n",
    "    network_name_selected = request.json['network_name_selected']\n",
    "    custom_params_selected = request.json['custom_params_selected']\n",
    "    training_params = request.json['training_params']\n",
    "    \n",
    "    \n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    dataset_fpath = data_repo.get_deep_network_info('dataset_fpath')\n",
    "    active_gpus = data_repo.get_inference_gpus()\n",
    "    instance_container = data_repo.get_deep_network_info('instance_container')\n",
    "\n",
    "    new_instance_container, log = network_controller.train(instance_container,\n",
    "                                                       dataset_fpath,\n",
    "                                                       num_gpus=len(active_gpus),\n",
    "                                                       cuda_devices=','.join(map(str, active_gpus)),\n",
    "                                                       batch_size=training_params['batch_size'],\n",
    "                                                       max_iter=training_params['max_iter'],\n",
    "                                                       lr=training_params['lr'],\n",
    "                                                       loss_type=training_params['loss_type'],\n",
    "                                                       optimiser=training_params['optimiser'],\n",
    "                                                       **custom_params_selected)\n",
    "    \n",
    "    _set_instance(network_name_selected)\n",
    "    logging.debug('Done training instance: {}'.format(network_name_selected))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "717b1909-229f-47a5-87c1-bcd8106e6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/go_finetuning/\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def go_finetuning():\n",
    "    \"\"\"\n",
    "        From request start training the network. \n",
    "    Request.json params: \n",
    "        network_name_selected (str) : \n",
    "        custom_params_selected (dict) :\n",
    "        training_params (dict) : \n",
    "    \"\"\"\n",
    "    # self._sentry_transaction = sentry_sdk.start_transaction(name='Training', op='deeplearning')\n",
    "    # self._sentry_transaction.__enter__() # why is it an object and do we tell it when to stop?\n",
    "    \n",
    "    network_name_selected = request.json['network_name_selected']\n",
    "    custom_params_selected = request.json['custom_params_selected']\n",
    "    training_params = request.json['training_params']\n",
    "    \n",
    "    \n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    dataset_fpath = data_repo.get_deep_network_info('dataset_fpath')\n",
    "    active_gpus = data_repo.get_inference_gpus()\n",
    "    instance_container = data_repo.get_deep_network_info('instance_container')\n",
    "\n",
    "    new_instance_container, log = network_controller.finetune(instance_container,\n",
    "                                                       dataset_fpath,\n",
    "                                                       num_gpus=len(active_gpus),\n",
    "                                                       cuda_devices=','.join(map(str, active_gpus)),\n",
    "                                                       batch_size=training_params['batch_size'],\n",
    "                                                       max_iter=training_params['max_iter'],\n",
    "                                                       lr=training_params['lr'],\n",
    "                                                       loss_type=training_params['loss_type'],\n",
    "                                                       optimiser=training_params['optimiser'],\n",
    "                                                       **custom_params_selected)\n",
    "    \n",
    "    _set_instance(network_name_selected)\n",
    "    logging.debug('Done training instance: {}'.format(network_name_selected))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97154446-6194-4676-bded-84822471dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def destroy_instance():\n",
    "    network_controller = _get_network_controller()\n",
    "    network_controller.destroy_network_instance(self._network_instance_name)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32a6f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route(\"/deep/network/export_network\", methods=[\"POST\"])\n",
    "# @cross_origin()\n",
    "def export_network():\n",
    "    \"\"\"\n",
    "        path should have extension '.model.tar.gz'\n",
    "    \"\"\"\n",
    "    network_name = request.json['export_network_name']\n",
    "    export_network_path = request.json['export_network_path'] # with new name\n",
    "    \n",
    "    network_controller = _get_network_controller()\n",
    "    \n",
    "    if not network_controller:\n",
    "        return handle_exception('Unable toload Network Controller. Make sure workspace is loaded.')\n",
    "    \n",
    "    if network_name not in network_controller.network_models:\n",
    "        return handle_exception('Network name not in network models list. {}'.format(str(e)))\n",
    "    \n",
    "    # exporting model\n",
    "    try:\n",
    "        network_controller.export_model(network_name, export_network_path)\n",
    "    except Exception as e:\n",
    "        return handle_exception('Unable to export network. {} {}'.format(str(e), export_network_path))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2840a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# host mode?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7f4fc",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d081d588-f727-4c4c-9afa-a32bb8509ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=training_params['batch_size'],\n",
    "# max_iter=training_params['max_iter'],\n",
    "# lr=training_params['lr'],\n",
    "# loss_type=training_params['loss_type'],\n",
    "# optimiser=training_params['optimiser'],\n",
    "\n",
    "# _loss = {\n",
    "#     'Cross Entropy': 'CrossEntropy',\n",
    "#     'Dice': 'Dice',\n",
    "#     'Cross Entropy + Dice': 'DicePlusXEnt',\n",
    "# }\n",
    "\n",
    "# _optimiser = {'Adam': 'adam', 'Gradient Descent': 'gradientdescent'}\n",
    "\n",
    "training_params = {\n",
    "    'batch_size': (1,1), \n",
    "    'max_iter': 10,\n",
    "    'lr': .2,\n",
    "    'loss_type': 'Dice',\n",
    "    'optimiser': 'gradientdescent'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55724997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting data that would come as input from the @app ['POST'] routes\n",
    "request.set_json({'workspace_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace',\n",
    " 'import_dataset_path': '/home/brunocarlos_lnls/work/images/datasets/dataset_augmented.h5',\n",
    " 'cache_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace/tmp',\n",
    " 'import_network_name':'mynewvnet',\n",
    " 'import_network_path':'/home/brunocarlos_lnls/work/anot/temp/legacy/frozen/my_frozen_vnet.model.tar.gz',\n",
    " 'export_network_name':'unet2d',\n",
    " 'export_network_path':'/home/brunocarlos_lnls/work/anot/temp/web/workspace/frozen/any_name.model.tar.gz',\n",
    " 'training_params': training_params\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ff5a340-9689-4793-94f8-000f9d6bfebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workspace_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace',\n",
       " 'import_dataset_path': '/home/brunocarlos_lnls/work/images/datasets/dataset_augmented.h5',\n",
       " 'cache_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace/tmp',\n",
       " 'import_network_name': 'mynewvnet',\n",
       " 'import_network_path': '/home/brunocarlos_lnls/work/anot/temp/legacy/frozen/my_frozen_vnet.model.tar.gz',\n",
       " 'export_network_name': 'unet2d',\n",
       " 'export_network_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace/frozen/any_name.model.tar.gz',\n",
       " 'training_params': {'batch_size': (1, 1),\n",
       "  'max_iter': 10,\n",
       "  'lr': 0.2,\n",
       "  'loss_type': 'Dice',\n",
       "  'optimiser': 'gradientdescent'}}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "16b0a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we have to load the workspace in data_repo, which is done in other module of the frontend\n",
    "# setting workspace\n",
    "\n",
    "load_workspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff38ef4",
   "metadata": {},
   "source": [
    "looking if the workspace path is written on data_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "754d0ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:44:11.474358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:11.474722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:11.474990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:11.475274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:11.475517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:11.475736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 1435 MB memory:  -> device: 0, name: NVIDIA GeForce MX450, pci bus id: 0000:05:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'success'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_set_network_controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "31512dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['newvnet', 'unet3d', 'vnet', 'mynewvnet', 'unet2d']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_nets = get_available_networks()\n",
    "avail_nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5f0c8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_params = get_network_params(avail_nets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7336e68c-8e1a-4dfe-b146-8b2c39b3e393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Patch Size': {'type': 'Group',\n",
       "  'value': {'xy': {'type': 'Combo',\n",
       "    'argname': 'patch_size__xy',\n",
       "    'value': ['32,32', '64,64', '128,128', '256,256', '512,512']},\n",
       "   'z': {'type': 'Combo',\n",
       "    'argname': 'patch_size__z',\n",
       "    'value': ['16', '32', '64', '128', '256', '512']}}},\n",
       " 'Drop Classifier': {'type': 'Combo',\n",
       "  'argname': 'drop_classifier',\n",
       "  'value': ['No', 'Yes']}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avail_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "63095e8b-8da5-4366-b9fc-9b9ba4fa5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params_selected = {'patch_size__xy': '32,32', 'patch_size__z': '16', 'drop_classifier': 'yes'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ef014578-40fe-4450-ad32-f5c13c231958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'workspace_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace',\n",
       " 'import_dataset_path': '/home/brunocarlos_lnls/work/images/datasets/dataset_augmented.h5',\n",
       " 'cache_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace/tmp',\n",
       " 'import_network_name': 'mynewvnet',\n",
       " 'import_network_path': '/home/brunocarlos_lnls/work/anot/temp/legacy/frozen/my_frozen_vnet.model.tar.gz',\n",
       " 'export_network_name': 'unet2d',\n",
       " 'export_network_path': '/home/brunocarlos_lnls/work/anot/temp/web/workspace/frozen/any_name.model.tar.gz',\n",
       " 'training_params': {'batch_size': (1, 1),\n",
       "  'max_iter': 10,\n",
       "  'lr': 0.2,\n",
       "  'loss_type': 'Dice',\n",
       "  'optimiser': 'gradientdescent'},\n",
       " 'custom_params_selected': {'patch_size__xy': '32,32',\n",
       "  'patch_size__z': '16',\n",
       "  'drop_classifier': 'yes'}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.append_json({'custom_params_selected': custom_params_selected})\n",
    "request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c9c93188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Patch Size': {'type': 'Group',\n",
       "  'value': {'xy': {'type': 'Combo',\n",
       "    'argname': 'patch_size__xy',\n",
       "    'value': ['32,32', '64,64', '128,128', '256,256', '512,512']},\n",
       "   'z': {'type': 'Combo',\n",
       "    'argname': 'patch_size__z',\n",
       "    'value': ['16', '32', '64', '128', '256', '512']}}},\n",
       " 'Drop Classifier': {'type': 'Combo',\n",
       "  'argname': 'drop_classifier',\n",
       "  'value': ['No', 'Yes']}}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_network() # reads from request.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7d17c5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/tables/leaf.py:367: PerformanceWarning: The Leaf ``/data`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  warnings.warn(\"\"\"\\\n",
      "/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/tables/leaf.py:367: PerformanceWarning: The Leaf ``/label`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  warnings.warn(\"\"\"\\\n",
      "/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/tables/leaf.py:367: PerformanceWarning: The Leaf ``/weight`` is exceeding the maximum recommended rowsize (104857600 bytes);\n",
      "be ready to see PyTables asking for *lots* of memory and possibly slow\n",
      "I/O.  You may want to reduce the rowsize by trimming the value of\n",
      "dimensions that are orthogonal (and preferably close) to the *main*\n",
      "dimension of this leave.  Alternatively, in case you have specified a\n",
      "very small/large chunksize, you may want to increase/decrease it.\n",
      "  warnings.warn(\"\"\"\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0\n",
      "data\n",
      "label\n",
      "weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'#_images': 1,\n",
       " '#_samples': 600,\n",
       " 'Dimensions': (100, 100, 10),\n",
       " 'data_mean': 33933.76104676667,\n",
       " 'data_std': 3807.4199842073185,\n",
       " 'data_min': 0.0,\n",
       " 'data_max': 40819.0,\n",
       " '#_classes': 2,\n",
       " '#_labels': 2,\n",
       " 'hist': array([39300672, 20699328]),\n",
       " 'weight_mean': 1.000000000137226,\n",
       " 'weight_std': 1.3722600833591476e-10,\n",
       " 'weight_min': 1.0,\n",
       " 'weight_max': 1.0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1e024d24-2894-4d3d-b40a-efbb4e4893ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "request.append_json({'network_name_selected': 'mynewvnet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b9aa8ef8-54b8-40a7-8411-3a1070da7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_instance('mynewvnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d750cb6-f9c5-4450-a25d-20d299423e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go to train ...\n",
      "mkdirs ...\n",
      "copying data ...\n",
      "####################\n",
      "Prune things away ...\n",
      "/home/brunocarlos_lnls/work/anot/temp/web/workspace/networks/mynewvnet/niftynet/models/checkpoint\n",
      "No checkpoint found\n",
      "Copying 600 samples from 1 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 15:44:36.647159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:36.648014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:36.648595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:36.649188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:36.649782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 15:44:36.650268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 1435 MB memory:  -> device: 0, name: NVIDIA GeForce MX450, pci bus id: 0000:05:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying time: 1.8363680839538574\n",
      "run this net ...\n",
      "run process ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streaming: True\n",
      "Done training instance: mynewvnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"sscDeepsirius/niftynet/niftynet_helper.py\", line 87, in sscDeepsirius.niftynet.niftynet_helper.run_niftynet\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/niftynet/engine/application_driver.py\", line 174, in initialise_application\n",
      "    self.app.initialise_dataset_loader(\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/niftynet/application/segmentation_application.py\", line 99, in initialise_dataset_loader\n",
      "    self.readers = [\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/niftynet/application/segmentation_application.py\", line 100, in <listcomp>\n",
      "    ImageReader(reader_names).initialise(\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/niftynet/io/image_reader.py\", line 179, in initialise\n",
      "    self.output_list, self._file_list = _filename_to_image_list(\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/niftynet/io/image_reader.py\", line 408, in _filename_to_image_list\n",
      "    print_progress_bar(idx,\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/site-packages/niftynet/utilities/util_common.py\", line 423, in print_progress_bar\n",
      "    print('\\r%s |%s| %s%% %s' % (prefix, bars, percent, suffix), end='\\r')\n",
      "  File \"sscDeepsirius/utils/processutils.py\", line 24, in sscDeepsirius.utils.processutils.TeeOut.write\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"sscDeepsirius/utils/processutils.py\", line 62, in sscDeepsirius.utils.processutils.Processify.__call__\n",
      "  File \"sscDeepsirius/niftynet/niftynet_helper.py\", line 90, in sscDeepsirius.niftynet.niftynet_helper.run_niftynet\n",
      "  File \"sscDeepsirius/utils/processutils.py\", line 24, in sscDeepsirius.utils.processutils.TeeOut.write\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"sscDeepsirius/utils/processutils.py\", line 24, in sscDeepsirius.utils.processutils.TeeOut.write\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"sscDeepsirius/utils/processutils.py\", line 70, in sscDeepsirius.utils.processutils.Processify.__call__\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 211, in send\n",
      "    self._send_bytes(_ForkingPickler.dumps(obj))\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/brunocarlos_lnls/.conda/envs/webdev-clone/lib/python3.9/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0f7ba8a7-b7ec-4236-bbd9-b678cc776749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_repo.get_inference_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a71c1f4c-a9bb-4515-a617-9dfa16ed7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = data_repo.get_deep_network_info('instance_container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "37ef1b19-0660-478d-b0fd-75747bbcacb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mynewvnet'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4e29fa67-56fe-4c77-85c7-fd0098c21a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = _get_network_controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f5d1099d-58df-4023-96ff-401c440a817a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'Host mode')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc.network_instance_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e04007-7fb6-4a25-8211-1f67f22b07bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1fd38f56a45b4af55475ed01d2e420e5da8cc6f5d5f3c61fa71b248bde1c6e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
